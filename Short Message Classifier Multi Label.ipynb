{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message Classifier, multi class, multi label\n",
    "Gilbert François Duivesteijn (gilbert@deep-impact.ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/dt_c111012.gif\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from lib.utils import plot_confusion_matrix\n",
    "from lib.utils import plot_y_proba\n",
    "from lib.utils import show_pred_proba\n",
    "np.set_printoptions(precision=3, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classes = {\n",
    "    1: 'late/early',\n",
    "    2: 'holidays',\n",
    "    3: 'home office',\n",
    "    4: 'med app',\n",
    "    5: 'ill',\n",
    "    6: 'business',\n",
    "    7: 'in office',\n",
    "    8: 'miscellaneous'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library functions\n",
    "\n",
    "Some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "\n",
    "def stemmed(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "def mask_integers(text):\n",
    "    return re.sub(r'\\d+', '_NUMBER', text)\n",
    "\n",
    "\n",
    "def mask_times(text):\n",
    "    \"\"\"\n",
    "    Replaces times written like 12:50, 1PM, 4:15am, etc to _time token.\n",
    "    :param    text    Input text\n",
    "    :return           Output text with replaced times.\n",
    "    \"\"\"\n",
    "    re_time1 = '\\d{1,2}[:.]\\d{2}(?:am|pm|AM|PM)'\n",
    "    re_time2 = '\\d{1,2}[:.]\\d{2}'\n",
    "    re_time3 = '\\d{1,2}(?:am|pm|AM|PM)'\n",
    "    rec_time = re.compile(re_time1 + '|' + re_time2 + '|' + re_time3)\n",
    "    return re.sub(rec_time, '_TIME', text)\n",
    "\n",
    "\n",
    "def mask_emojis(text):\n",
    "    \"\"\"\n",
    "    Replaces all different emojis to _emoji token.\n",
    "    :param    text    Input text\n",
    "    :return           Output text with replaced emojis.    \n",
    "    \"\"\"\n",
    "    re_icons = ':[a-z-_]*:'\n",
    "    re_ldsd = '\\<(.*?)\\>'\n",
    "    rec_icons = re.compile(re_icons + \"|\" + re_ldsd)\n",
    "    return re.sub(rec_icons, '_EMOJI', text)\n",
    "\n",
    "\n",
    "def mask_all(text):\n",
    "    text = mask_times(text)\n",
    "    text = mask_emojis(text)\n",
    "    text = mask_integers(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def train_and_test(steps, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Trains and tests the pipeline with the given steps. \n",
    "    :param steps:       List of operations inside the pipeline.\n",
    "    :param X_train:     Training data\n",
    "    :param X_test:      Training labels\n",
    "    :param y_train:     Testing data\n",
    "    :param y_test:      Testing labels\n",
    "    :return:            Trained model\n",
    "    \"\"\"\n",
    "    pipeline = Pipeline(steps)\n",
    "    folds = 10\n",
    "    xval_score = cross_val_score(pipeline, X_train, y_train, cv=folds, n_jobs=-1)\n",
    "    \n",
    "    xv_min = np.min(xval_score)\n",
    "    xv_max = np.max(xval_score)\n",
    "    xv_mean = np.mean(xval_score)\n",
    "    xv_std = np.std(xval_score)\n",
    "    print('{} fold Cross Validation Score: <{:.2f}, {:.2f}>; µ={:.2f}'.format(folds, xv_min, xv_max, xv_mean))\n",
    "    pipeline = pipeline.fit(X_train, y_train)\n",
    "    print('Score on test set: {:.2f}'.format(pipeline.score(X_test, y_test)))\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def tag_message(pipeline, message):\n",
    "    y_pred = pipeline.predict([message])[0]\n",
    "    print('{:>20} | {}'.format(dict_classes[y_pred], message))\n",
    "    \n",
    "\n",
    "def multitag_message(pipeline, message):\n",
    "    y_pred = pipeline.predict([message])[0]\n",
    "    tags = [dict_classes[i+1] for i, yi in enumerate(y_pred) if yi == 1]\n",
    "    # Remove `misc` tag if the list contains other tags as well.\n",
    "    if len(tags) > 1 and dict_classes[8] in tags:\n",
    "        del tags[tags.index(dict_classes[8])]\n",
    "    print('{:>30} | {}'.format('['+'] ['.join(tags)+']', message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the annotated data\n",
    "\n",
    "Load the data and split the data in a training and test set. \n",
    "\n",
    "_Note that we load the same annotated dataset as we did for training the single class predictions._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages = pd.read_pickle('data/messages-cls.pkl')\n",
    "\n",
    "# Remove all rows which have no annotation\n",
    "df_messages = df_messages.dropna()\n",
    "\n",
    "# Convert the classification column to unsigned int, in case it is stored as string\n",
    "df_messages['class'] = df_messages.loc[:, 'class'].astype(np.uint8).values\n",
    "\n",
    "X = df_messages['text']\n",
    "y = df_messages['class']\n",
    "\n",
    "print('[.] Number of training samples: {}'.format(len(X)))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "df_messages.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi label predictions with probabilities\n",
    "\n",
    "Let's review our first classifier and see if we can modify it to do multi class predictions. Change the `LinearSVC` to `SVC` with linear kernel and set the parameter `probability` to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vectorizer', CountVectorizer()),\n",
    "         ('classifier', SVC(kernel='linear', probability=True, random_state=1))]\n",
    "pipeline1 = train_and_test(steps, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = ['I do home office.']\n",
    "y_pred_list = pipeline1.predict_proba(doc_list)\n",
    "show_pred_proba(y_pred_list, doc_list, dict_classes, threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the challenge is how to set the value of the threshold. Possibilities are:\n",
    "- Fixed threshold, e.g. Label is true if $y_{pred}^i > 0.2$\n",
    "- Dynamic threshold, e.g. Label is true if $y_{pred}^i > \\frac{1}{4}\\max(y_{pred})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    'I go a bit earlier, have an appointment at the doctor.  Then I will do home office',\n",
    "]\n",
    "y_pred_list = pipeline1.predict_proba(doc_list)\n",
    "\n",
    "show_pred_proba(y_pred_list, doc_list, dict_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi label predictions with 1-vs-rest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages = pd.read_pickle('data/messages-cls-mc.pkl')\n",
    "\n",
    "# Remove all rows which have no annotation\n",
    "df_messages = df_messages.dropna()\n",
    "\n",
    "# Convert the classification column to unsigned int, in case it is stored as string\n",
    "df_messages['class'] = df_messages.loc[:, 'class'].astype(np.uint8).values\n",
    "\n",
    "X = df_messages['text']\n",
    "y = df_messages['multiclass']\n",
    "df_messages.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the categorical class vectors to binary vectors with `MultiLabelBinarizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym = MultiLabelBinarizer().fit_transform(y)\n",
    "print(ym.shape)\n",
    "ym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, ym, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose one of the step options and see the difference in accuracy.\n",
    "\n",
    "# steps = [('vectorizer', CountVectorizer()),\n",
    "#          ('classifier', OneVsRestClassifier(SVC(kernel='linear')))]\n",
    "\n",
    "steps = [('vectorizer', CountVectorizer(ngram_range=(1,2), \n",
    "                                        preprocessor=mask_all, \n",
    "                                        analyzer=stemmed, \n",
    "                                        stop_words='english')),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', OneVsRestClassifier(SVC(kernel='linear')))]\n",
    "pipeline2 = train_and_test(steps, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score seems not so great. Let's look at some misclassified documents to see what is going on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_list = pipeline2.predict(X_test).tolist()\n",
    "y_test_list = y_test.tolist()\n",
    "for index in range(len(y_pred_list))[:10]:\n",
    "    if y_pred_list[index] != y_test_list[index]:\n",
    "        print('[pred]: ', y_pred_list[index])\n",
    "        print('[true]: ', y_test_list[index])\n",
    "        print('[doc ]: ', X_test.iloc[index])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting the `predictions` and compare them to the `true` values, the model is doing better than the cross validation score and test score indicate. One reason for the low scores is that _all_ elements of the $y_{pred}^i$ vector have to be the same as $y_{true}^i$. This is much harder than matching a _one-hot_ vector, like in the case of multi class single label classification. Another reason is that some of the annotations from the dataset are open for debate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the model do with some test documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitag_message(pipeline2, 'I don\\'t feel well, stay home and don\\'t come to the office.')\n",
    "multitag_message(pipeline2, 'My alarm clock was not set properly. I come to the office asap.')\n",
    "multitag_message(pipeline2, 'It is my scheduled day off, see you on Tuesday.')\n",
    "multitag_message(pipeline2, 'I\\'m having a terrible headache, I stay home and work from here.')\n",
    "multitag_message(pipeline2, 'I work at home on Tuesday.')\n",
    "multitag_message(pipeline2, 'In the morning I\\'ve a meeting with IBM, I\\'ll be back at 1pm.')\n",
    "multitag_message(pipeline2, 'I\\'m off, see you tomorrow.')\n",
    "multitag_message(pipeline2, 'get well soon!')\n",
    "multitag_message(pipeline2, 'I\\'m away for a long lunch between 12:00 and 15:30')\n",
    "multitag_message(pipeline2, 'I\\'ve an appointment at 12:00 at the physiotherapy.')\n",
    "multitag_message(pipeline2, 'I go to the doctor and will be online again after 18:00.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi label predictions with sentence tokenization\n",
    "\n",
    "### Step 1: Build a sentence tokenizer\n",
    "\n",
    "Let's make the following assumption:\n",
    "- A document has only multiple class labels when it has multiple sentences.\n",
    "- Every sentence contains only one class label.\n",
    "\n",
    "For this model, every document will tokenized in sentences, then every sentence will be classified with a multi class, single label classifier.\n",
    "\n",
    "NLTK has a sentence tokenizer, but combined sentences are not splitted. We have to do this ourselves. We will use part of speech (POS) tagging to analyse the sentence and see if it can be splitted or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenizer(text, verbose=False):\n",
    "    # Some input checking.\n",
    "    if not isinstance(text, str):\n",
    "        print('[!] Input type should be a string, not a {}'.format(type(text)))\n",
    "        exit(1)\n",
    "        \n",
    "    # Split sentences with NLTK\n",
    "    text_list_1 = nltk.sent_tokenize(text)\n",
    "    \n",
    "    # Split sentences with our POS tagging method\n",
    "    text_list_2 = []\n",
    "    for text in text_list_1:\n",
    "        text_list_2 += custom_sentence_tokenizer(text, verbose)\n",
    "    \n",
    "    return text_list_2\n",
    "\n",
    "\n",
    "def custom_sentence_tokenizer(text, verbose=False):\n",
    "    # container for final result\n",
    "    new_split = []\n",
    "    \n",
    "    # Split sentences by a comma, 'and' and 'or'.\n",
    "    text_list = re.split(',| and | or | but | \\(', text)\n",
    "    \n",
    "    # Remove white spaces and empty string elements from the list\n",
    "    text_list = [x.strip() for x in text_list]\n",
    "    text_list = list(filter(None, text_list))\n",
    "        \n",
    "    # Append first list element to the new list.\n",
    "    new_split.append(text_list[0])\n",
    "    \n",
    "    # Check if the splits are valid sentences. If not, glue the parts together again.\n",
    "    for index in range(1, len(text_list)):\n",
    "        \n",
    "        # Keep the split if both parts of the sentences contain a verb.\n",
    "        if has_verb(text_list[index-1], verbose) and has_verb(text_list[index], verbose):\n",
    "            new_split.append(text_list[index])\n",
    "        # Glue the parts together again, since POS requirements are not met.\n",
    "        else:\n",
    "            new_split[-1] += ' ' + text_list[index]\n",
    "    \n",
    "    if verbose:\n",
    "        print('[.] Input sentence:')\n",
    "        print('    ', text)\n",
    "        print('[.] Output sentence(s):')\n",
    "        print('    ', new_split)\n",
    "    return new_split\n",
    "    \n",
    "\n",
    "def has_verb(sentence, verbose=False):\n",
    "    pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    if verbose:\n",
    "        print(pos_tagged)\n",
    "    if 'VB' in [tag[1][:2] for tag in pos_tagged]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def split_sentences_in_dataframe(df, verbose=False):\n",
    "    new_df = pd.DataFrame()\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        text_list = sentence_tokenizer(text, verbose)\n",
    "        for text_part in text_list:\n",
    "            new_row = row.copy()\n",
    "            new_row['text'] = text_part\n",
    "            new_df = new_df.append(new_row)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"I'm afraid I can't explain myself, sir. Because I am not myself, you see?\"\n",
    "doc = \"I have to leave around 11am, having a meeting with alice and will be back after 15:00.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence tokenization with NLTK. Combined sentences are not tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.sent_tokenize(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence tokenization with our own implementation. Combined sentences are now tokenized as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokenizer(doc, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Tokenize sentences of the original data and annotate\n",
    "\n",
    "Use the above mentioned method to tokenize the documents and start annotating (by hand) the new tokenized documents. When this is done, we can continue with step 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Load new annotated data and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_messages = pd.read_pickle('data/messages-cls-ms.pkl')\n",
    "df_messages.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the class column to int, it might be stored as a string\n",
    "df_messages['class'] = df_messages.loc[:, 'class'].astype(np.uint8).values\n",
    "print('Number of documents: {}'.format(len(df_messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_messages['text'], \n",
    "                                                    df_messages['class'], \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WARNING* Running the gridsearch takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "steps = [('vectorizer', CountVectorizer()),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', LinearSVC())]\n",
    "pipeline3 = Pipeline(steps)\n",
    "\n",
    "params = {\n",
    "    'vectorizer__tokenizer': [None, nltk.tokenize.word_tokenize],\n",
    "    'vectorizer__analyzer' : ['word', stemmed],\n",
    "    'vectorizer__stop_words': [None, nltk.corpus.stopwords.words('english'), 'english'],\n",
    "    'vectorizer__ngram_range': [(1, 1), (1, 2), (2, 2), (1, 3)],\n",
    "    'vectorizer__preprocessor': [None, mask_all, mask_integers, mask_times, mask_emojis],\n",
    "    'classifier__C': np.logspace(-2, 2, 5),\n",
    "    'classifier__gamma': np.logspace(-5, 3, 9)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipeline3, params, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_params_)\n",
    "y_pred = gs.predict(X_test)\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "print('Score on the test set: {:.2f}'.format(gs.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vectorizer', CountVectorizer(analyzer=stemmed,\n",
    "                                        ngram_range=(1,2),\n",
    "                                        stop_words='english',\n",
    "                                        preprocessor=mask_all)),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', LinearSVC(C=1))]\n",
    "pipeline4 = train_and_test(steps, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline4.predict(X_test)\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_pred=y_pred, y_true=y_test)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=dict_classes.values(), normalize=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel3_message(model, doc):\n",
    "    doc_list = sentence_tokenizer(doc)\n",
    "    y_pred = pipeline4.predict(doc_list)\n",
    "    # Remove double class predictions\n",
    "    y_pred = list(set(y_pred))\n",
    "    tags = [dict_classes[i] for i in y_pred]\n",
    "    # Remove `misc` tag if the list contains other tags as well.\n",
    "    if len(tags) > 1 and dict_classes[8] in tags:\n",
    "        del tags[tags.index(dict_classes[8])]\n",
    "    print('{:>30} | {}'.format('['+'] ['.join(tags)+']', doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel3_message(pipeline4, 'My alarm clock was not set properly. I come to the office asap.')\n",
    "multilabel3_message(pipeline4, 'It is my scheduled day off, see you on Tuesday.')\n",
    "multilabel3_message(pipeline4, 'Not feeling well today, I stay home and work from here.')\n",
    "multilabel3_message(pipeline4, 'I work at home on Tuesday.')\n",
    "multilabel3_message(pipeline4, 'This morning I have a meeting at ACME.')\n",
    "multilabel3_message(pipeline4, 'I\\'m off, see you tomorrow.')\n",
    "multilabel3_message(pipeline4, 'Get well soon!')\n",
    "multilabel3_message(pipeline4, 'I\\'m away for a long lunch between 12:00 and 15:30')\n",
    "multilabel3_message(pipeline4, 'I\\'ve an appointment at 12:00 at the physiotherapy.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    " [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "[1, 2, 3, 4]  [5, 6, 7, 8]\n",
    "\n",
    "[1, 2] [3, 4] [5, 6] [7, 8]\n",
    "\n",
    "[1][2] [3][4] [5][6] [7][8]\n",
    "\n",
    "probability=True, random_state=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi label predictions with sentence tokenization and ensembles\n",
    "\n",
    "\n",
    "Another idea is to train an ensemble of machines with different hyper parameters. It smoothes out the incluence of a specific hyperparameter and might give a better generalized probability.\n",
    "\n",
    "In the example below, we train 6 machines with different settings and elements in the pipeline. A good approach is to do e.g.:\n",
    "- pipeline with count vectorizer only\n",
    "- pipeline with count vectorizer and TF-IDF transformer\n",
    "- pipeline with count vectorizer and Okapi BM25 transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('vectorizer', CountVectorizer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline10 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "          \n",
    "steps = [('vectorizer', CountVectorizer()),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline11 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "\n",
    "steps = [('vectorizer', CountVectorizer(analyzer=stemmed)),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline12 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "\n",
    "steps = [('vectorizer', CountVectorizer(analyzer=stemmed, preprocessor=mask_all, ngram_range=(1,3), stop_words='english')),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline13 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "\n",
    "steps = [('vectorizer', CountVectorizer(analyzer=stemmed, preprocessor=mask_all, ngram_range=(1,2))),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline14 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "\n",
    "steps = [('vectorizer', CountVectorizer(preprocessor=mask_all, stop_words='english')),\n",
    "         ('transformer', TfidfTransformer()),\n",
    "         ('classifier', SVC(kernel='linear', C=1, probability=True, random_state=1))]\n",
    "pipeline15 = train_and_test(steps, X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [pipeline10, pipeline11, pipeline12, pipeline13, pipeline14, pipeline15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(models, doc):\n",
    "    y_pred_list = []\n",
    "    for model in models:\n",
    "        # Computes a probability vector for every model\n",
    "        y_pred_list.append(model.predict_proba([doc]))\n",
    "    # Stack all vectors to a 2D matrix\n",
    "    y_pred_mat = np.vstack(y_pred_list)\n",
    "    # Sum all predictions and take the argmax as your final prediction\n",
    "    y_pred = np.sum(y_pred_mat, axis=0)\n",
    "    y_pred = np.argmax(y_pred) + 1\n",
    "    return y_pred\n",
    "\n",
    "def multilabel4_tag(models, doc):\n",
    "    doc_list = sentence_tokenizer(doc)\n",
    "    y_pred = [ensemble_predict(models, token) for token in doc_list]\n",
    "    # Remove double class predictions\n",
    "    y_pred = list(set(y_pred))\n",
    "    tags = [dict_classes[i] for i in y_pred]\n",
    "    # Remove `misc` tag if the list contains other tags as well.\n",
    "    if len(tags) > 1 and dict_classes[8] in tags:\n",
    "        del tags[tags.index(dict_classes[8])]\n",
    "    print('{:>30} | {}'.format('['+'] ['.join(tags)+']', doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m = np.vstack(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred_m, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel4_tag(models, 'My alarm clock was not set properly. I come to the office asap.')\n",
    "multilabel4_tag(models, 'It is my scheduled day off, see you on Tuesday.')\n",
    "multilabel4_tag(models, 'Not feeling well today, I stay home and work from here.')\n",
    "multilabel4_tag(models, 'I work at home on Tuesday.')\n",
    "multilabel4_tag(models, 'This morning I have a meeting at ACME.')\n",
    "multilabel4_tag(models, 'I\\'m off, see you tomorrow.')\n",
    "multilabel4_tag(models, 'Get well soon!')\n",
    "multilabel4_tag(models, 'I\\'m away for a long lunch between 12:00 and 15:30')\n",
    "multilabel4_tag(models, 'I\\'ve an appointment at 12:00 at the physiotherapy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [ensemble_predict(models, X_test.iloc[i]) for i in range(len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=y_pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes=dict_classes.values(), normalize=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
